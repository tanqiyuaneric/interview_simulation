{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample0': {'major': 'Nursing', 'grade': 'second', 'answer1': '\"Liberal arts, from my understanding, is the education that provides us with a variety of knowledge, rather than the education that teaches us specific skills.\\\\n\"', 'answer2': '\"\\\\\"I think the most important part of liberal arts education is that it encourages us to think critically. Instead of simply accepting the information given to us, we need to learn to question it, and to think about it in a variety of ways.\\\\\\\\n\\\\\"\\\\n\"'}, 'sample1': {'major': 'Engineering', 'grade': 'fourth', 'answer1': '\"Sure, I think liberal arts is the study of the humanities and the social sciences. It includes subjects like history, philosophy, literature, and art.\\\\n\"', 'answer2': '\"\\\\\"I\\'ve found that studying liberal arts has given me a broader perspective on the world and has made me more empathetic. It\\'s helped me to understand and appreciate different cultures and points of view.\\\\\\\\n\\\\\"\\\\n\"'}, 'sample2': {'major': 'Pre-Medical or Pre-Health Sciences', 'grade': 'first', 'answer1': '\"Liberal arts is a broad educational curriculum that is not tied to professional or career-specific studies. Instead, it focuses on developing critical thinking, communication, and problem-solving skills through the study of humanities, social sciences, and natural sciences. It emphasizes the importance of learning for learning\\'s sake, rather than solely for the purpose of acquiring job skills.\\\\n\"', 'answer2': '\"I have found that liberal arts education has challenged me to think critically about the world around me and to question my assumptions. It has also enabled me to communicate effectively and to express myself clearly, both in writing and orally. Additionally, the problem-solving skills I have developed through my liberal arts education have been invaluable in helping me approach complex issues from multiple perspectives and identify creative solutions.\\\\n\"'}, 'sample3': {'major': 'Pre-Medical or Pre-Health Sciences', 'grade': 'third', 'answer1': '\"Liberal arts is a way of thinking, a way of approaching life and solving problems. It\\'s not just about learning facts and figures, but about learning how to think critically and creatively, how to communicate effectively, and how to adapt to new situations. Liberal arts is about developing a broad set of skills and knowledge that can be applied in many different fields and situations.\\\\n\"', 'answer2': '\"\\\\\"I\\'ve found that studying liberal arts has helped me develop a more holistic view of the world and the issues we face. It has taught me to look beyond the surface and to consider multiple perspectives. I\\'ve been able to apply these skills in my everyday life, whether it\\'s analyzing a political issue or simply having a more informed conversation with friends.\\\\\\\\n\\\\\"\\\\n\"'}, 'sample4': {'major': 'Mathematics', 'grade': 'fourth', 'answer1': '\"Personally, I think liberal arts is a way of learning that focuses on the development of the whole person and is more broad and interdisciplinary than traditional professional education. It aims to foster critical thinking, communication skills, and creative problem-solving abilities, rather than focusing on specific career skills. Liberal arts education also emphasizes the importance of the individual and the value of diversity and inclusion.\\\\n\"', 'answer2': '\"\\\\\"I have found liberal arts education to be incredibly valuable in my own education and career. As a student at Harvard, I have had the opportunity to take courses in a wide range of disciplines, from literature and history to computer science and economics. These courses have not only taught me specific skills and knowledge, but have also helped me develop critical thinking, communication, and problem-solving abilities that are applicable in many different contexts. Additionally, Harvard\\'s emphasis on diversity and inclusion has exposed me to a wide range of perspectives and experiences, which has helped me become a more well-rounded and empathetic person.\\\\\\\\n\\\\\"\\\\n\"'}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('samples.json', 'r') as json_file:\n",
    "    loaded_data = json.load(json_file)\n",
    "\n",
    "print(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'smart_open' has no attribute 'local_file' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Import necessary libraries\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m corpora\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LdaModel\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnltk\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtokenize\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m word_tokenize\n",
      "File \u001B[1;32mD:\\anoconda\\envs\\code_gen\\lib\\site-packages\\gensim\\__init__.py:11\u001B[0m\n\u001B[0;32m      7\u001B[0m __version__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m4.3.2\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlogging\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001B[38;5;66;03m# noqa:F401\u001B[39;00m\n\u001B[0;32m     14\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgensim\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m logger\u001B[38;5;241m.\u001B[39mhandlers:  \u001B[38;5;66;03m# To ensure reload() doesn't add another one\u001B[39;00m\n",
      "File \u001B[1;32mD:\\anoconda\\envs\\code_gen\\lib\\site-packages\\gensim\\parsing\\__init__.py:4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"This package contains functions to preprocess raw text\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mporter\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PorterStemmer  \u001B[38;5;66;03m# noqa:F401\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (  \u001B[38;5;66;03m# noqa:F401\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     preprocess_documents,\n\u001B[0;32m      6\u001B[0m     preprocess_string,\n\u001B[0;32m      7\u001B[0m     read_file,\n\u001B[0;32m      8\u001B[0m     read_files,\n\u001B[0;32m      9\u001B[0m     remove_stopwords,\n\u001B[0;32m     10\u001B[0m     split_alphanum,\n\u001B[0;32m     11\u001B[0m     stem_text,\n\u001B[0;32m     12\u001B[0m     strip_multiple_whitespaces,\n\u001B[0;32m     13\u001B[0m     strip_non_alphanum,\n\u001B[0;32m     14\u001B[0m     strip_numeric,\n\u001B[0;32m     15\u001B[0m     strip_punctuation,\n\u001B[0;32m     16\u001B[0m     strip_short,\n\u001B[0;32m     17\u001B[0m     strip_tags,\n\u001B[0;32m     18\u001B[0m )\n",
      "File \u001B[1;32mD:\\anoconda\\envs\\code_gen\\lib\\site-packages\\gensim\\parsing\\preprocessing.py:26\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mstring\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mglob\u001B[39;00m\n\u001B[1;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparsing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mporter\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PorterStemmer\n\u001B[0;32m     30\u001B[0m STOPWORDS \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfrozenset\u001B[39m([\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msix\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjust\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mless\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbeing\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindeed\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mover\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmove\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124manyway\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfour\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnot\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mown\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthrough\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124musing\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfifty\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwhere\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmill\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124monly\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfind\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbefore\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mone\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwhose\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msystem\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhow\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msomewhere\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmake\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124monce\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     59\u001B[0m ])\n",
      "File \u001B[1;32mD:\\anoconda\\envs\\code_gen\\lib\\site-packages\\gensim\\utils.py:37\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msparse\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msmart_open\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;28mopen\u001B[39m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__ \u001B[38;5;28;01mas\u001B[39;00m gensim_version\n\u001B[0;32m     41\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;18m__name__\u001B[39m)\n",
      "File \u001B[1;32mD:\\anoconda\\envs\\code_gen\\lib\\site-packages\\smart_open\\__init__.py:34\u001B[0m\n\u001B[0;32m     31\u001B[0m logger\u001B[38;5;241m.\u001B[39maddHandler(logging\u001B[38;5;241m.\u001B[39mNullHandler())\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msmart_open\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m version  \u001B[38;5;66;03m# noqa: E402\u001B[39;00m\n\u001B[1;32m---> 34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msmart_open_lib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;28mopen\u001B[39m, parse_uri, smart_open, register_compressor  \u001B[38;5;66;03m# noqa: E402\u001B[39;00m\n\u001B[0;32m     36\u001B[0m _WARNING \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124msmart_open.s3_iter_bucket is deprecated and will stop functioning\u001B[39m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;124min a future version. Please import iter_bucket from the smart_open.s3 module instead:\u001B[39m\n\u001B[0;32m     38\u001B[0m \n\u001B[0;32m     39\u001B[0m \u001B[38;5;124m    from smart_open.s3 import iter_bucket as s3_iter_bucket\u001B[39m\n\u001B[0;32m     40\u001B[0m \n\u001B[0;32m     41\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m     42\u001B[0m _WARNED \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mD:\\anoconda\\envs\\code_gen\\lib\\site-packages\\smart_open\\smart_open_lib.py:35\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msmart_open\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlocal_file\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mso_file\u001B[39;00m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msmart_open\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompression\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mso_compression\u001B[39;00m\n\u001B[1;32m---> 35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msmart_open\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m doctools\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msmart_open\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m transport\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# For backwards compatibility and keeping old unit tests happy.\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n",
      "File \u001B[1;32mD:\\anoconda\\envs\\code_gen\\lib\\site-packages\\smart_open\\doctools.py:21\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mre\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compression\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m transport\n\u001B[0;32m     23\u001B[0m PLACEHOLDER \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m    smart_open/doctools.py magic goes here\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mextract_kwargs\u001B[39m(docstring):\n",
      "File \u001B[1;32mD:\\anoconda\\envs\\code_gen\\lib\\site-packages\\smart_open\\transport.py:22\u001B[0m\n\u001B[0;32m     18\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m     20\u001B[0m NO_SCHEME \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 22\u001B[0m _REGISTRY \u001B[38;5;241m=\u001B[39m {NO_SCHEME: \u001B[43msmart_open\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlocal_file\u001B[49m}\n\u001B[0;32m     23\u001B[0m _ERRORS \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m     24\u001B[0m _MISSING_DEPS_ERROR \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124mYou are trying to use the \u001B[39m\u001B[38;5;132;01m%(module)s\u001B[39;00m\u001B[38;5;124m functionality of smart_open\u001B[39m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;124mbut you do not have the correct \u001B[39m\u001B[38;5;132;01m%(module)s\u001B[39;00m\u001B[38;5;124m dependencies installed. Try:\u001B[39m\n\u001B[0;32m     26\u001B[0m \n\u001B[0;32m     27\u001B[0m \u001B[38;5;124m    pip install smart_open[\u001B[39m\u001B[38;5;132;01m%(module)s\u001B[39;00m\u001B[38;5;124m]\u001B[39m\n\u001B[0;32m     28\u001B[0m \n\u001B[0;32m     29\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n",
      "\u001B[1;31mAttributeError\u001B[0m: partially initialized module 'smart_open' has no attribute 'local_file' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Sample dataset (replace this with your own data)\n",
    "documents = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\"\n",
    "]\n",
    "\n",
    "# Preprocessing: Tokenization, lowercasing, and removing stopwords and punctuation\n",
    "def preprocess(doc):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    tokens = word_tokenize(doc.lower())\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [word.translate(translator) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to all documents\n",
    "processed_docs = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Create a dictionary representation of the documents\n",
    "dictionary = corpora.Dictionary(processed_docs)\n",
    "\n",
    "# Convert the documents to a bag-of-words representation\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Build the LDA model\n",
    "lda_model = LdaModel(corpus, num_topics=3, id2word=dictionary, passes=15)\n",
    "\n",
    "# Print the topics and their corresponding words\n",
    "for topic_id, topic in lda_model.print_topics():\n",
    "    print(f'Topic #{topic_id}: {topic}')\n",
    "\n",
    "# Assign topics to documents\n",
    "for i, doc in enumerate(corpus):\n",
    "    print(f\"Document #{i}: {documents[i]}\")\n",
    "    print(f\"Assigned Topics: {lda_model[doc]}\\n\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
